{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "80759e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import urllib.request\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c127f484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.BeautifulSoup"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "website = urllib.request.urlopen('https://analytics.usa.gov').read()\n",
    "soup = BeautifulSoup(website, 'html.parser')\n",
    "type(soup)  # should return bs4.BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "368c9c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=\"en\">\n",
      " <!-- Initalize title and data source variables -->\n",
      " <head>\n",
      "  <!--\n",
      "\n",
      "    Hi! Welcome to our source code.\n",
      "\n",
      "    This dashboard uses data from the Digital Analytics Program, a US\n",
      "    government team inside the General Services Administration.\n",
      "\n",
      "\n",
      "    For a detailed tech breakdown of how 18F and friends built this site:\n",
      "\n",
      "    https://18f.gsa.gov/2015/03/19/how-we-built-analytics-usa-gov/\n",
      "\n",
      "\n",
      "    This is a fully open source project, and your contributions are welcome.\n",
      "\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(soup.prettify()[0:500])  # prints the HTML content in a structured format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "49befd52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/\n",
      "/about\n",
      "/definitions\n",
      "https://open.gsa.gov/api/dap/\n",
      "/visualizations\n",
      "/data\n"
     ]
    }
   ],
   "source": [
    "for link in soup.find_all('a', href=True):\n",
    "    print(link['href'])\n",
    "\n",
    "# here we are using the find_all() method to search for all anchor tags with an href attribute and printing the value of the href attribute for each tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ade6f550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\njust_the_text = soup.get_text()\\nprint(just_the_text[0:500])  # prints the text content of the HTML\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "just_the_text = soup.get_text()\n",
    "print(just_the_text[0:500])  # prints the text content of the HTML\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e2bdfdba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=\"en\">\n",
      " <!-- Initalize title and data source variables -->\n",
      " <head>\n",
      "  <!--\n",
      "\n",
      "    Hi! Welcome to our source code.\n",
      "\n",
      "    This dashboard uses data from the Digital Analytics Program, a US\n",
      "    government team inside the General Services Administration.\n",
      "\n",
      "\n",
      "    For a detailed tech breakdown of how 18F and friends built this site:\n",
      "\n",
      "    https://18f.gsa.gov/2015/03/19/how-we-built-analytics-usa-gov/\n",
      "\n",
      "\n",
      "    This is a fully open source project, and your contributions are welcome.\n",
      "\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(soup.prettify()[0:500])  # prints the HTML content in a structured format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31358e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "file = open(\"parsed_data.txt\", \"w\", encoding='utf-8')\n",
    "for link in soup.find_all('a', href=True):\n",
    "    file.write(link['href'] + \"\\n\")\n",
    "file.close()\n",
    "'''\n",
    "\n",
    "# here we are writing all the href attributes of anchor tags to a text file named \"parsed_data.txt\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learning",
   "language": "python",
   "name": "learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
